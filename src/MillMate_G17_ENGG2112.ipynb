{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bba3f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9927290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (10000, 14)\n",
      "\n",
      "NaN check:\n",
      " UDI                        0\n",
      "Product ID                 0\n",
      "Type                       0\n",
      "Air temperature [K]        0\n",
      "Process temperature [K]    0\n",
      "Rotational speed [rpm]     0\n",
      "Torque [Nm]                0\n",
      "Tool wear [min]            0\n",
      "Machine failure            0\n",
      "TWF                        0\n",
      "HDF                        0\n",
      "PWF                        0\n",
      "OSF                        0\n",
      "RNF                        0\n",
      "dtype: int64\n",
      "\n",
      "Shape after removing NaN rows: (10000, 14)\n",
      "\n",
      "Z-score scaled sample:\n",
      "   UDI Product ID  Type  Air temperature [K]  Process temperature [K]  \\\n",
      "0    1     M14860     1            -0.952389                -0.947360   \n",
      "1    2     L47181     0            -0.902393                -0.879959   \n",
      "2    3     L47182     0            -0.952389                -1.014761   \n",
      "3    4     L47183     0            -0.902393                -0.947360   \n",
      "4    5     L47184     0            -0.902393                -0.879959   \n",
      "\n",
      "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
      "0                0.068185     0.282200        -1.695984                0    0   \n",
      "1               -0.729472     0.633308        -1.648852                0    0   \n",
      "2               -0.227450     0.944290        -1.617430                0    0   \n",
      "3               -0.590021    -0.048845        -1.586009                0    0   \n",
      "4               -0.729472     0.001313        -1.554588                0    0   \n",
      "\n",
      "   HDF  PWF  OSF  RNF  \n",
      "0    0    0    0    0  \n",
      "1    0    0    0    0  \n",
      "2    0    0    0    0  \n",
      "3    0    0    0    0  \n",
      "4    0    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "#Data Prepping\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"../data/ai4i2020.csv\")\n",
    "df.head()\n",
    "\n",
    "# How many rows & colums + NaN check\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"\\nNaN check:\\n\", df.isna().sum())\n",
    "\n",
    "# Drop any NaN rows if exist\n",
    "df.dropna(inplace=True)\n",
    "print(\"\\nShape after removing NaN rows:\", df.shape)\n",
    "\n",
    "# Encode product quality labels (L, M, H) numerically as 0, 1 & 2\n",
    "if 'Type' in df.columns:\n",
    "    df['Type'] = df['Type'].map({'L': 0, 'M': 1, 'H': 2})\n",
    "\n",
    "# Select continuous numerical columns\n",
    "continuous_cols = ['Air temperature [K]', 'Process temperature [K]',\n",
    "                   'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "\n",
    "# Apply Z-score scaling\n",
    "scaler_z = StandardScaler()\n",
    "df_z_scaled = df.copy()\n",
    "df_z_scaled[continuous_cols] = scaler_z.fit_transform(df[continuous_cols])\n",
    "\n",
    "# Final output\n",
    "print(\"\\nZ-score scaled sample:\")\n",
    "print(df_z_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c580cc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Target distribution (0=L,1=M,2=H): Counter({0: 6000, 1: 2997, 2: 1003})\n",
      "Target distribution (L/M/H as 0/1/2): Counter({0: 6000, 1: 2997, 2: 1003})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 125\u001b[0m\n\u001b[1;32m    123\u001b[0m rows, prob_store \u001b[38;5;241m=\u001b[39m [], {}\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, pipe \u001b[38;5;129;01min\u001b[39;00m strategies\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 125\u001b[0m     cv_f1, cv_mcc, cv_pr, cv_roc \u001b[38;5;241m=\u001b[39m cv_scores_multiclass(pipe, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    126\u001b[0m     pipe\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m    127\u001b[0m     prob \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "Cell \u001b[0;32mIn[6], line 118\u001b[0m, in \u001b[0;36mcv_scores_multiclass\u001b[0;34m(model, X, y, cv)\u001b[0m\n\u001b[1;32m    116\u001b[0m     mcc_list\u001b[38;5;241m.\u001b[39mappend(matthews_corrcoef(y[va], pred))\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# macro PR-AUC & ROC-AUC with OvR\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     prauc_list\u001b[38;5;241m.\u001b[39mappend(average_precision_score(y[va], prob, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    119\u001b[0m     rocauc_list\u001b[38;5;241m.\u001b[39mappend(roc_auc_score(y[va], prob, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(f1_list)), \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(mcc_list)), \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(prauc_list)), \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(rocauc_list))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:234\u001b[0m, in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_label=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpos_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid label. It should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpresent_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m average_precision \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    232\u001b[0m     _binary_uninterpolated_average_precision, pos_label\u001b[38;5;241m=\u001b[39mpos_label\n\u001b[1;32m    233\u001b[0m )\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    235\u001b[0m     average_precision, y_true, y_score, average, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_base.py:72\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "#Multiclass L/M/H (Quality) Pipeline\n",
    "!pip -q install imbalanced-learn\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report, matthews_corrcoef, f1_score,\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# 1) Load and define target/features (NO leakage)\n",
    "# Reuse an existing df if present; otherwise read the CSV in the working dir.\n",
    "if 'df' not in globals():\n",
    "    df = pd.read_csv('ai4i2020.csv')\n",
    "\n",
    "# Target: Quality \"Type\" with values L/M/H\n",
    "# robust target extraction for Type (L/M/H)\n",
    "assert 'Type' in df.columns, \"Missing 'Type' column.\"\n",
    "\n",
    "t = df['Type']\n",
    "\n",
    "def coerce_type_to_012(s):\n",
    "    # case 1: already numeric 0/1/2\n",
    "    try:\n",
    "        vals = pd.to_numeric(s, errors='coerce')\n",
    "        if set(pd.unique(vals.dropna())) <= {0,1,2}:\n",
    "            return vals.astype(int).to_numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # case 2: strings like 'L','M','H' (with potential spaces/mixed case)\n",
    "    s2 = s.astype(str).str.strip().str.upper()\n",
    "    mapped = s2.map({'L':0, 'M':1, 'H':2})\n",
    "    if mapped.isna().any():\n",
    "        print(\"Unrecognized Type values:\",\n",
    "              sorted(s2[mapped.isna()].unique().tolist())[:20])\n",
    "        raise ValueError(\"Type contains values other than L/M/H or 0/1/2.\")\n",
    "    return mapped.astype(int).to_numpy()\n",
    "\n",
    "y = coerce_type_to_012(t)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Target distribution (0=L,1=M,2=H):\", Counter(y))\n",
    "\n",
    "\n",
    "# Use only sensor/process features to avoid leakage from IDs and failure labels\n",
    "sensor_cols = ['Air temperature [K]','Process temperature [K]',\n",
    "               'Rotational speed [rpm]','Torque [Nm]','Tool wear [min]']\n",
    "X = df[sensor_cols].copy()\n",
    "\n",
    "print(\"Target distribution (L/M/H as 0/1/2):\", Counter(y))\n",
    "\n",
    "# 2) Split and scaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 3) Strategies (imbalance handling for multiclass)\n",
    "# Note:\n",
    "# - SMOTE works in multiclass via OvR under the hood.\n",
    "# - Class weights are applied per-class in the base estimator.\n",
    "# - BalancedRandomForest performs class-balanced resampling inside each tree.\n",
    "strategies = {\n",
    "    \"Baseline LogReg\": ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('clf', LogisticRegression(max_iter=2000))\n",
    "    ]),\n",
    "    \"SMOTE + LogReg\": ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(max_iter=2000))\n",
    "    ]),\n",
    "    \"ClassWeight LogReg\": ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('clf', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
    "    ]),\n",
    "    \"SMOTE + RandomForest\": ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1))\n",
    "    ]),\n",
    "    \"BalancedRandomForest\": ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('clf', BalancedRandomForestClassifier(\n",
    "            n_estimators=600, random_state=42, n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 4) Cross-validation helper (stratified)\n",
    "def cv_scores_multiclass(model, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Returns mean macro-F1, MCC, macro PR-AUC, and ROC-AUC (OvR) via stratified K-fold CV.\n",
    "    For PR/ROC AUC we use probability estimates and one-vs-rest aggregation.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    f1_list, mcc_list, prauc_list, rocauc_list = [], [], [], []\n",
    "    for tr, va in skf.split(X, y):\n",
    "        model.fit(X.iloc[tr], y[tr])\n",
    "        prob = model.predict_proba(X.iloc[va])  # shape [n, 3]\n",
    "        pred = np.argmax(prob, axis=1)\n",
    "        # macro-F1 & MCC (multiclass)\n",
    "        f1_list.append(f1_score(y[va], pred, average='macro'))\n",
    "        mcc_list.append(matthews_corrcoef(y[va], pred))\n",
    "        # macro PR-AUC & ROC-AUC with OvR\n",
    "        prauc_list.append(average_precision_score(y[va], prob, average='macro'))\n",
    "        rocauc_list.append(roc_auc_score(y[va], prob, multi_class='ovr', average='macro'))\n",
    "    return float(np.mean(f1_list)), float(np.mean(mcc_list)), float(np.mean(prauc_list)), float(np.mean(rocauc_list))\n",
    "\n",
    "# 5) Run all strategies, evaluate on test, collect results\n",
    "rows, prob_store = [], {}\n",
    "for name, pipe in strategies.items():\n",
    "    cv_f1, cv_mcc, cv_pr, cv_roc = cv_scores_multiclass(pipe, X_train, y_train, cv=5)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    prob = pipe.predict_proba(X_test)\n",
    "    pred = np.argmax(prob, axis=1)\n",
    "\n",
    "    test_macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "    test_mcc      = matthews_corrcoef(y_test, pred)\n",
    "    test_pr_auc   = average_precision_score(y_test, prob, average='macro')\n",
    "    test_roc_auc  = roc_auc_score(y_test, prob, multi_class='ovr', average='macro')\n",
    "\n",
    "    row = {\n",
    "        \"model\": name,\n",
    "        \"cv_macroF1\": cv_f1,\n",
    "        \"cv_MCC\": cv_mcc,\n",
    "        \"cv_macroPR_AUC\": cv_pr,\n",
    "        \"cv_ROC_AUC_OvR\": cv_roc,\n",
    "        \"test_macroF1\": test_macro_f1,\n",
    "        \"test_MCC\": test_mcc,\n",
    "        \"test_macroPR_AUC\": test_pr_auc,\n",
    "        \"test_ROC_AUC_OvR\": test_roc_auc\n",
    "    }\n",
    "    rows.append(row)\n",
    "    prob_store[name] = prob\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print({k: round(v,4) if isinstance(v, float) else v for k,v in row.items()})\n",
    "    print(classification_report(y_test, pred, digits=4, target_names=['L','M','H'], zero_division=0))\n",
    "\n",
    "df_res = pd.DataFrame(rows).sort_values(\n",
    "    by=[\"test_macroPR_AUC\",\"test_macroF1\",\"test_MCC\",\"test_ROC_AUC_OvR\"],\n",
    "    ascending=False\n",
    ")\n",
    "display(df_res)\n",
    "\n",
    "# 6) Confusion matrix (best model)\n",
    "best_name = df_res.iloc[0]['model']\n",
    "best_prob = prob_store[best_name]\n",
    "best_pred = np.argmax(best_prob, axis=1)\n",
    "cm = confusion_matrix(y_test, best_pred, labels=[0,1,2], normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['L','M','H'])\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "plt.title(f'Normalized Confusion Matrix — {best_name}')\n",
    "plt.show()\n",
    "\n",
    "# 7) OvR curves for the best model\n",
    "# PR curves (one-vs-rest) per class\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "for c, cname in enumerate(['L','M','H']):\n",
    "    P, R, _ = precision_recall_curve((y_test==c).astype(int), best_prob[:,c])\n",
    "    plt.plot(R, P, label=cname)\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title(f'PR Curves (OvR) — {best_name}')\n",
    "plt.grid(True); plt.legend(); plt.show()\n",
    "\n",
    "# ROC curves (one-vs-rest) per class\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "for c, cname in enumerate(['L','M','H']):\n",
    "    fpr, tpr, _ = roc_curve((y_test==c).astype(int), best_prob[:,c])\n",
    "    plt.plot(fpr, tpr, label=cname)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title(f'ROC Curves (OvR) — {best_name}')\n",
    "plt.grid(True); plt.legend(); plt.show()\n",
    "\n",
    "# 8) Export table\n",
    "df_res.to_csv('failure_imbalance_comparison.csv', index=False)\n",
    "print('Saved: failure_imbalance_comparison.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f67343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine failure\n",
    "!pip -q install imbalanced-learn\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, precision_recall_curve, roc_curve,\n",
    "    confusion_matrix, classification_report, matthews_corrcoef, f1_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "\n",
    "# 1) Load & define target/features (anti-leak)\n",
    "# If a DataFrame named `df` already exists, reuse it; otherwise read from CSV.\n",
    "if 'df' not in globals():\n",
    "    df = pd.read_csv('ai4i2020.csv')\n",
    "\n",
    "# Target: Machine failure (highly imbalanced ~3.4% positives)\n",
    "assert 'Machine failure' in df.columns, \"Missing 'Machine failure' column\"\n",
    "y = df['Machine failure'].astype(int).values\n",
    "\n",
    "# Use only process/sensor features to avoid leakage.\n",
    "# Drop identifiers, quality label, and individual failure-type flags from features.\n",
    "sensor_cols = ['Air temperature [K]','Process temperature [K]',\n",
    "               'Rotational speed [rpm]','Torque [Nm]','Tool wear [min]']\n",
    "X = df[sensor_cols].copy()\n",
    "\n",
    "print('Class distribution (overall):', Counter(y))\n",
    "\n",
    "# 2) Split & scaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 3) Define models/strategies\n",
    "# Recommended for extreme imbalance: ensemble methods with built-in resampling,\n",
    "# plus SMOTE/ADASYN and class_weight baselines for comparison.\n",
    "strategies = {\n",
    "    # A) Ensemble methods (recommended)\n",
    "    'BalancedRF': ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('clf', BalancedRandomForestClassifier(\n",
    "            n_estimators=600, max_depth=None, random_state=42, n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    'EasyEnsemble': ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('clf', EasyEnsembleClassifier(\n",
    "            n_estimators=10, random_state=42, n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    # B) Oversampling + linear model\n",
    "    'SMOTE + LogReg': ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(max_iter=2000, class_weight=None))\n",
    "    ]),\n",
    "    'ADASYN + LogReg': ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('adasyn', ADASYN(random_state=42)),\n",
    "        ('clf', LogisticRegression(max_iter=2000, class_weight=None))\n",
    "    ]),\n",
    "    # C) Class weighting only (no resampling)\n",
    "    'ClassWeight LogReg': ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('clf', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
    "    ]),\n",
    "    'ClassWeight RF': ImbPipeline([\n",
    "        ('sc', scaler),\n",
    "        ('clf', RandomForestClassifier(\n",
    "            n_estimators=600, class_weight='balanced_subsample', random_state=42, n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 4) Cross-validation helper\n",
    "def cv_scores(model, X, y, cv=5):\n",
    "    \"\"\"Return mean ROC-AUC, PR-AUC, F1 (at best-F1 threshold), and MCC via stratified K-fold CV.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    roc_list, pr_list, f1_list, mcc_list = [], [], [], []\n",
    "    for tr, va in skf.split(X, y):\n",
    "        model.fit(X.iloc[tr], y[tr])\n",
    "        prob = model.predict_proba(X.iloc[va])[:,1]\n",
    "        # choose threshold that maximizes F1 on the fold\n",
    "        P, R, T = precision_recall_curve(y[va], prob)\n",
    "        f1s = 2*P*R/(P+R+1e-12)\n",
    "        thr = T[np.nanargmax(f1s)] if len(T)>0 else 0.5\n",
    "        pred = (prob >= thr).astype(int)\n",
    "        roc_list.append(roc_auc_score(y[va], prob))\n",
    "        pr_list.append(average_precision_score(y[va], prob))  # PR-AUC\n",
    "        f1_list.append(f1_score(y[va], pred))\n",
    "        mcc_list.append(matthews_corrcoef(y[va], pred))\n",
    "    return np.mean(roc_list), np.mean(pr_list), np.mean(f1_list), np.mean(mcc_list)\n",
    "\n",
    "def evaluate_on_test(model, Xtr, ytr, Xte, yte, prefer='f1'):\n",
    "    \"\"\"Fit on train, predict probabilities on test, tune threshold by preference, and report metrics.\"\"\"\n",
    "    model.fit(Xtr, ytr)\n",
    "    prob = model.predict_proba(Xte)[:,1]\n",
    "    # threshold tuning: choose by 'f1' (default), 'recall', or 'precision'\n",
    "    P, R, T = precision_recall_curve(yte, prob)\n",
    "    T = np.r_[T, 1.0]\n",
    "    if prefer=='recall':\n",
    "        idx = np.argmax(R)\n",
    "    elif prefer=='precision':\n",
    "        idx = np.argmax(P)\n",
    "    else:\n",
    "        f1s = 2*P*R/(P+R+1e-12)\n",
    "        idx = np.nanargmax(f1s)\n",
    "    thr = float(T[idx])\n",
    "    pred = (prob >= thr).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        'ROC_AUC': roc_auc_score(yte, prob),\n",
    "        'PR_AUC' : average_precision_score(yte, prob),\n",
    "        'F1'     : f1_score(yte, pred),\n",
    "        'Recall' : recall_score(yte, pred),\n",
    "        'Precision': precision_score(yte, pred),\n",
    "        'MCC'    : matthews_corrcoef(yte, pred),\n",
    "        'threshold': thr,\n",
    "        'conf_mat': confusion_matrix(yte, pred)\n",
    "    }\n",
    "    return metrics, prob, pred\n",
    "\n",
    "# 5) Run all strategies & collect results\n",
    "rows, probs_dict = [], {}\n",
    "for name, pipe in strategies.items():\n",
    "    cv_roc, cv_pr, cv_f1, cv_mcc = cv_scores(pipe, X_train, y_train, cv=5)\n",
    "    test_metrics, prob, pred = evaluate_on_test(pipe, X_train, y_train, X_test, y_test, prefer='f1')\n",
    "    row = {'model': name, 'cv_ROC_AUC': cv_roc, 'cv_PR_AUC': cv_pr, 'cv_F1': cv_f1, 'cv_MCC': cv_mcc}\n",
    "    row.update({f'test_{k}': v for k,v in test_metrics.items() if k!='conf_mat'})\n",
    "    rows.append(row)\n",
    "    probs_dict[name] = prob\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print({k: (round(v,4) if isinstance(v,float) else v) for k,v in row.items() if 'conf' not in k})\n",
    "    print('Confusion matrix:\\n', test_metrics['conf_mat'])\n",
    "\n",
    "df_res = pd.DataFrame(rows).sort_values(by=['test_PR_AUC','test_MCC','test_F1'], ascending=False)\n",
    "display(df_res)\n",
    "\n",
    "# 6) Curves for TOP-3\n",
    "top3 = df_res.head(3)['model'].tolist()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for name in top3:\n",
    "    p = probs_dict[name]\n",
    "    P, R, _ = precision_recall_curve(y_test, p)\n",
    "    plt.plot(R, P, label=name)\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('PR Curves (Top-3)')\n",
    "plt.grid(True); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for name in top3:\n",
    "    p = probs_dict[name]\n",
    "    fpr, tpr, _ = roc_curve(y_test, p)\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curves (Top-3)')\n",
    "plt.grid(True); plt.legend(); plt.show()\n",
    "\n",
    "# 7) Export\n",
    "df_res.to_csv('failure_imbalance_comparison.csv', index=False)\n",
    "print('Saved: failure_imbalance_comparison.csv')\n",
    "\n",
    "# Tip: if your project prioritizes catching positives, change `prefer='recall'`\n",
    "# inside evaluate_on_test (above), or sort by ['test_Recall','test_PR_AUC','test_MCC'].\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
